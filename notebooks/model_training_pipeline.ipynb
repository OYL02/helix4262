{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing modularized functions\n",
    "df_path = \"\" # edit this to select dataset\n",
    "df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df: pd.DataFrame):\n",
    "    '''\n",
    "    Removes transcript_name and gene_id columns.\n",
    "    Add or remove columns as required.\n",
    "    '''\n",
    "    df1 = df.drop([\"transcript_name\", \"gene_id\", \"nucleotide_seq\"], axis=1)\n",
    "    return df1\n",
    "\n",
    "def trigram_tokenize(df:pd.DataFrame, n):\n",
    "    '''\n",
    "    to apply trigram on column \"nucleotide_seq\" using TfidfVectorizer\n",
    "    '''\n",
    "    corpus = df['nucleotide_seq']\n",
    "    v_nucleotide_seq = TfidfVectorizer(analyzer='char', ngram_range=(n,n)).fit_transform(corpus)\n",
    "    v = pd.DataFrame(scipy.sparse.csr_matrix.toarray(v_nucleotide_seq)) # convert sparse matrix to array\n",
    "\n",
    "    # creating dictionary to easily add vectorized sequence features as columns to dataframe\n",
    "    new_nucleotide_data = dict() \n",
    "    for i in range(v.shape[1]):\n",
    "        key = \"s\" + str(i)\n",
    "        new_nucleotide_data[key] = v[i]\n",
    "\n",
    "    df_final = df.assign(**new_nucleotide_data)\n",
    "    \n",
    "    return df_final #returns dataframe with vectorized nucleotide features as columns\n",
    "\n",
    "def data_split(df:pd.DataFrame):\n",
    "    '''\n",
    "    splits data by gene into train and test sets according to the percentage given.\n",
    "    '''\n",
    "    X = df.drop([\"label\"], axis=1)\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=2, random_state=0, test_size=0.2)\n",
    "    train_i, test_i = next(gss.split(X,y,groups=X.gene_id))\n",
    "\n",
    "    X_train = X.loc[train_i]\n",
    "    y_train = y.loc[train_i]\n",
    "\n",
    "    X_test = X.loc[test_i]\n",
    "    y_test = y.loc[test_i]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def standardize_data(X_train, X_test):\n",
    "    '''\n",
    "    Standardizes numerical features while leaving non-numerical features unchanged.\n",
    "    Assumes X is pandas DataFrames.\n",
    "    '''\n",
    "    x_columns = X_train.columns\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X_train.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', 'passthrough', categorical_cols)  # Leave categorical columns unchanged\n",
    "        ])\n",
    "    \n",
    "    # Apply the column transformer\n",
    "    X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns = x_columns)\n",
    "    X_test_scaled = preprocessor.transform(X_test)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns = x_columns)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def synthetic_oversampling(X_train, y_train):\n",
    "    '''\n",
    "    Uses SMOTE to oversample the minority class.\n",
    "    '''\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, y_train_resampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stringing together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_all(df):\n",
    "    \"\"\"\n",
    "    Purpose: Setting up the pipeline? to drop unnecessary columns, followed by vectorizing, splitting, standardising and oversampling\n",
    "    \"\"\"\n",
    "    # Vectorization\n",
    "    tokenized_df = trigram_tokenize(df, 3)\n",
    "\n",
    "    # Train-test split and remove the \"transcript_name\", \"gene_id\", \"nucleotide_seq\" columns\n",
    "    Xtrain, Xtest, ytrain, ytest = data_split(tokenized_df)\n",
    "    Xtrain = remove_columns(Xtrain)\n",
    "    Xtest = remove_columns(Xtest)\n",
    "\n",
    "    # Scaling Xtrain and Xtest with Scaler fitted on Xtrain\n",
    "    Xtrain_scaled, Xtest_scaled = standardize_data(Xtrain, Xtest)\n",
    "\n",
    "    # SMOTE on training set \n",
    "    Xtrain_resampled, ytrain_resampled = synthetic_oversampling(Xtrain_scaled, ytrain)\n",
    "    \n",
    "    return Xtrain_resampled, Xtest_scaled, ytrain_resampled, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_all(df)\n",
    "X_train.to_csv(\"../dataset/Xtrain.csv\", index = False)\n",
    "y_train.to_csv(\"../dataset/ytrain.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
